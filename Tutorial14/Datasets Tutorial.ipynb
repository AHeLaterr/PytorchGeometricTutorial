{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.datasets as datasets\n",
    "import torch_geometric.data as data\n",
    "import torch_geometric.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package torch_geometric.data in torch_geometric:\n",
      "\n",
      "NAME\n",
      "    torch_geometric.data\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    batch\n",
      "    cluster\n",
      "    data\n",
      "    dataloader\n",
      "    dataset\n",
      "    download\n",
      "    extract\n",
      "    graph_saint\n",
      "    in_memory_dataset\n",
      "    makedirs\n",
      "    sampler\n",
      "    shadow\n",
      "    temporal\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        torch_geometric.data.data.Data\n",
      "            torch_geometric.data.batch.Batch\n",
      "        torch_geometric.data.temporal.TemporalData\n",
      "    torch.utils.data.dataloader.DataLoader(builtins.object)\n",
      "        torch_geometric.data.cluster.ClusterLoader\n",
      "        torch_geometric.data.dataloader.DataListLoader\n",
      "        torch_geometric.data.dataloader.DataLoader\n",
      "        torch_geometric.data.dataloader.DenseDataLoader\n",
      "        torch_geometric.data.graph_saint.GraphSAINTSampler\n",
      "            torch_geometric.data.graph_saint.GraphSAINTEdgeSampler\n",
      "            torch_geometric.data.graph_saint.GraphSAINTNodeSampler\n",
      "            torch_geometric.data.graph_saint.GraphSAINTRandomWalkSampler\n",
      "        torch_geometric.data.sampler.NeighborSampler\n",
      "        torch_geometric.data.sampler.RandomNodeSampler\n",
      "        torch_geometric.data.shadow.ShaDowKHopSampler\n",
      "    torch.utils.data.dataset.Dataset(builtins.object)\n",
      "        torch_geometric.data.cluster.ClusterData\n",
      "        torch_geometric.data.dataset.Dataset\n",
      "            torch_geometric.data.in_memory_dataset.InMemoryDataset\n",
      "    \n",
      "    class Batch(torch_geometric.data.data.Data)\n",
      "     |  Batch(batch=None, ptr=None, **kwargs)\n",
      "     |  \n",
      "     |  A plain old python object modeling a batch of graphs as one big\n",
      "     |  (disconnected) graph. With :class:`torch_geometric.data.Data` being the\n",
      "     |  base class, all its methods can also be used here.\n",
      "     |  In addition, single graphs can be reconstructed via the assignment vector\n",
      "     |  :obj:`batch`, which maps each node to its respective graph identifier.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Batch\n",
      "     |      torch_geometric.data.data.Data\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx)\n",
      "     |      Gets the data of the attribute :obj:`key`.\n",
      "     |  \n",
      "     |  __init__(self, batch=None, ptr=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_example(self, idx: int) -> torch_geometric.data.data.Data\n",
      "     |      Reconstructs the :class:`torch_geometric.data.Data` object at index\n",
      "     |      :obj:`idx` from the batch object.\n",
      "     |      The batch object must have been created via :meth:`from_data_list` in\n",
      "     |      order to be able to reconstruct the initial objects.\n",
      "     |  \n",
      "     |  index_select(self, idx: torch.Tensor) -> List[torch_geometric.data.data.Data]\n",
      "     |  \n",
      "     |  to_data_list(self) -> List[torch_geometric.data.data.Data]\n",
      "     |      Reconstructs the list of :class:`torch_geometric.data.Data` objects\n",
      "     |      from the batch object.\n",
      "     |      The batch object must have been created via :meth:`from_data_list` in\n",
      "     |      order to be able to reconstruct the initial objects.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_data_list(data_list, follow_batch=[], exclude_keys=[]) from builtins.type\n",
      "     |      Constructs a batch object from a python list holding\n",
      "     |      :class:`torch_geometric.data.Data` objects.\n",
      "     |      The assignment vector :obj:`batch` is created on the fly.\n",
      "     |      Additionally, creates assignment batch vectors for each key in\n",
      "     |      :obj:`follow_batch`.\n",
      "     |      Will exclude any keys given in :obj:`exclude_keys`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  num_graphs\n",
      "     |      Returns the number of graphs in the batch.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch_geometric.data.data.Data:\n",
      "     |  \n",
      "     |  __apply__(self, item, func)\n",
      "     |  \n",
      "     |  __call__(self, *keys)\n",
      "     |      Iterates over all attributes :obj:`*keys` in the data, yielding\n",
      "     |      their attribute names and content.\n",
      "     |      If :obj:`*keys` is not given this method will iterative over all\n",
      "     |      present attributes.\n",
      "     |  \n",
      "     |  __cat_dim__(self, key, value)\n",
      "     |      Returns the dimension for which :obj:`value` of attribute\n",
      "     |      :obj:`key` will get concatenated when creating batches.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This method is for internal use only, and should only be overridden\n",
      "     |          if the batch concatenation process is corrupted for a specific data\n",
      "     |          attribute.\n",
      "     |  \n",
      "     |  __contains__(self, key)\n",
      "     |      Returns :obj:`True`, if the attribute :obj:`key` is present in the\n",
      "     |      data.\n",
      "     |  \n",
      "     |  __inc__(self, key, value)\n",
      "     |      Returns the incremental count to cumulatively increase the value\n",
      "     |      of the next attribute of :obj:`key` when creating batches.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This method is for internal use only, and should only be overridden\n",
      "     |          if the batch concatenation process is corrupted for a specific data\n",
      "     |          attribute.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Iterates over all present attributes in the data, yielding their\n",
      "     |      attribute names and content.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Returns the number of all present attributes.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |      Sets the attribute :obj:`key` to :obj:`value`.\n",
      "     |  \n",
      "     |  apply(self, func, *keys)\n",
      "     |      Applies the function :obj:`func` to all tensor attributes\n",
      "     |      :obj:`*keys`. If :obj:`*keys` is not given, :obj:`func` is applied to\n",
      "     |      all present attributes.\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |  \n",
      "     |  coalesce(self)\n",
      "     |      \"Orders and removes duplicated entries from edge indices.\n",
      "     |  \n",
      "     |  contains_isolated_nodes(self)\n",
      "     |      Returns :obj:`True`, if the graph contains isolated nodes.\n",
      "     |  \n",
      "     |  contains_self_loops(self)\n",
      "     |      Returns :obj:`True`, if the graph contains self-loops.\n",
      "     |  \n",
      "     |  contiguous(self, *keys)\n",
      "     |      Ensures a contiguous memory layout for all attributes :obj:`*keys`.\n",
      "     |      If :obj:`*keys` is not given, all present attributes are ensured to\n",
      "     |      have a contiguous memory layout.\n",
      "     |  \n",
      "     |  cpu(self, *keys)\n",
      "     |      Copies all attributes :obj:`*keys` to CPU memory.\n",
      "     |      If :obj:`*keys` is not given, the conversion is applied to all present\n",
      "     |      attributes.\n",
      "     |  \n",
      "     |  cuda(self, device=None, non_blocking=False, *keys)\n",
      "     |      Copies all attributes :obj:`*keys` to CUDA memory.\n",
      "     |      If :obj:`*keys` is not given, the conversion is applied to all present\n",
      "     |      attributes.\n",
      "     |  \n",
      "     |  debug(self)\n",
      "     |  \n",
      "     |  is_coalesced(self)\n",
      "     |      Returns :obj:`True`, if edge indices are ordered and do not contain\n",
      "     |      duplicate entries.\n",
      "     |  \n",
      "     |  is_directed(self)\n",
      "     |      Returns :obj:`True`, if graph edges are directed.\n",
      "     |  \n",
      "     |  is_undirected(self)\n",
      "     |      Returns :obj:`True`, if graph edges are undirected.\n",
      "     |  \n",
      "     |  pin_memory(self, *keys)\n",
      "     |      Copies all attributes :obj:`*keys` to pinned memory.\n",
      "     |      If :obj:`*keys` is not given, the conversion is applied to all present\n",
      "     |      attributes.\n",
      "     |  \n",
      "     |  to(self, device, *keys, **kwargs)\n",
      "     |      Performs tensor dtype and/or device conversion to all attributes\n",
      "     |      :obj:`*keys`.\n",
      "     |      If :obj:`*keys` is not given, the conversion is applied to all present\n",
      "     |      attributes.\n",
      "     |  \n",
      "     |  to_dict(self)\n",
      "     |  \n",
      "     |  to_namedtuple(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from torch_geometric.data.data.Data:\n",
      "     |  \n",
      "     |  from_dict(dictionary) from builtins.type\n",
      "     |      Creates a data object from a python dictionary.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch_geometric.data.data.Data:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  keys\n",
      "     |      Returns all names of graph attributes.\n",
      "     |  \n",
      "     |  num_edge_features\n",
      "     |      Returns the number of features per edge in the graph.\n",
      "     |  \n",
      "     |  num_edges\n",
      "     |      Returns the number of edges in the graph.\n",
      "     |      For undirected graphs, this will return the number of bi-directional\n",
      "     |      edges, which is double the amount of unique edges.\n",
      "     |  \n",
      "     |  num_faces\n",
      "     |      Returns the number of faces in the mesh.\n",
      "     |  \n",
      "     |  num_features\n",
      "     |      Alias for :py:attr:`~num_node_features`.\n",
      "     |  \n",
      "     |  num_node_features\n",
      "     |      Returns the number of features per node in the graph.\n",
      "     |  \n",
      "     |  num_nodes\n",
      "     |      Returns or sets the number of nodes in the graph.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          The number of nodes in your data object is typically automatically\n",
      "     |          inferred, *e.g.*, when node features :obj:`x` are present.\n",
      "     |          In some cases however, a graph may only be given by its edge\n",
      "     |          indices :obj:`edge_index`.\n",
      "     |          PyTorch Geometric then *guesses* the number of nodes\n",
      "     |          according to :obj:`edge_index.max().item() + 1`, but in case there\n",
      "     |          exists isolated nodes, this number has not to be correct and can\n",
      "     |          therefore result in unexpected batch-wise behavior.\n",
      "     |          Thus, we recommend to set the number of nodes in your data object\n",
      "     |          explicitly via :obj:`data.num_nodes = ...`.\n",
      "     |          You will be given a warning that requests you to do so.\n",
      "    \n",
      "    class ClusterData(torch.utils.data.dataset.Dataset)\n",
      "     |  ClusterData(data, num_parts: int, recursive: bool = False, save_dir: Union[str, NoneType] = None, log: bool = True)\n",
      "     |  \n",
      "     |  Clusters/partitions a graph data object into multiple subgraphs, as\n",
      "     |  motivated by the `\"Cluster-GCN: An Efficient Algorithm for Training Deep\n",
      "     |  and Large Graph Convolutional Networks\"\n",
      "     |  <https://arxiv.org/abs/1905.07953>`_ paper.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      data (torch_geometric.data.Data): The graph data object.\n",
      "     |      num_parts (int): The number of partitions.\n",
      "     |      recursive (bool, optional): If set to :obj:`True`, will use multilevel\n",
      "     |          recursive bisection instead of multilevel k-way partitioning.\n",
      "     |          (default: :obj:`False`)\n",
      "     |      save_dir (string, optional): If set, will save the partitioned data to\n",
      "     |          the :obj:`save_dir` directory for faster re-use.\n",
      "     |          (default: :obj:`None`)\n",
      "     |      log (bool, optional): If set to :obj:`False`, will not log any\n",
      "     |          progress. (default: :obj:`True`)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ClusterData\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx)\n",
      "     |  \n",
      "     |  __init__(self, data, num_parts: int, recursive: bool = False, save_dir: Union[str, NoneType] = None, log: bool = True)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __permute_data__(self, data, node_idx, adj)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ClusterLoader(torch.utils.data.dataloader.DataLoader)\n",
      "     |  ClusterLoader(cluster_data, **kwargs)\n",
      "     |  \n",
      "     |  The data loader scheme from the `\"Cluster-GCN: An Efficient Algorithm\n",
      "     |  for Training Deep and Large Graph Convolutional Networks\"\n",
      "     |  <https://arxiv.org/abs/1905.07953>`_ paper which merges partioned subgraphs\n",
      "     |  and their between-cluster links from a large-scale graph data object to\n",
      "     |  form a mini-batch.\n",
      "     |  \n",
      "     |  .. note::\n",
      "     |  \n",
      "     |      Use :class:`torch_geometric.data.ClusterData` and\n",
      "     |      :class:`torch_geometric.data.ClusterLoader` in conjunction to\n",
      "     |      form mini-batches of clusters.\n",
      "     |      For an example of using Cluster-GCN, see\n",
      "     |      `examples/cluster_gcn_reddit.py <https://github.com/rusty1s/\n",
      "     |      pytorch_geometric/blob/master/examples/cluster_gcn_reddit.py>`_ or\n",
      "     |      `examples/cluster_gcn_ppi.py <https://github.com/rusty1s/\n",
      "     |      pytorch_geometric/blob/master/examples/cluster_gcn_ppi.py>`_.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      cluster_data (torch_geometric.data.ClusterData): The already\n",
      "     |          partioned data object.\n",
      "     |      **kwargs (optional): Additional arguments of\n",
      "     |          :class:`torch.utils.data.DataLoader`, such as :obj:`batch_size`,\n",
      "     |          :obj:`shuffle`, :obj:`drop_last` or :obj:`num_workers`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ClusterLoader\n",
      "     |      torch.utils.data.dataloader.DataLoader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __collate__(self, batch)\n",
      "     |  \n",
      "     |  __init__(self, cluster_data, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __setattr__(self, attr, val)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  multiprocessing_context\n",
      "    \n",
      "    class Data(builtins.object)\n",
      "     |  Data(x=None, edge_index=None, edge_attr=None, y=None, pos=None, normal=None, face=None, **kwargs)\n",
      "     |  \n",
      "     |  A plain old python object modeling a single graph with various\n",
      "     |  (optional) attributes:\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      x (Tensor, optional): Node feature matrix with shape :obj:`[num_nodes,\n",
      "     |          num_node_features]`. (default: :obj:`None`)\n",
      "     |      edge_index (LongTensor, optional): Graph connectivity in COO format\n",
      "     |          with shape :obj:`[2, num_edges]`. (default: :obj:`None`)\n",
      "     |      edge_attr (Tensor, optional): Edge feature matrix with shape\n",
      "     |          :obj:`[num_edges, num_edge_features]`. (default: :obj:`None`)\n",
      "     |      y (Tensor, optional): Graph or node targets with arbitrary shape.\n",
      "     |          (default: :obj:`None`)\n",
      "     |      pos (Tensor, optional): Node position matrix with shape\n",
      "     |          :obj:`[num_nodes, num_dimensions]`. (default: :obj:`None`)\n",
      "     |      normal (Tensor, optional): Normal vector matrix with shape\n",
      "     |          :obj:`[num_nodes, num_dimensions]`. (default: :obj:`None`)\n",
      "     |      face (LongTensor, optional): Face adjacency matrix with shape\n",
      "     |          :obj:`[3, num_faces]`. (default: :obj:`None`)\n",
      "     |  \n",
      "     |  The data object is not restricted to these attributes and can be extented\n",
      "     |  by any other additional data.\n",
      "     |  \n",
      "     |  Example::\n",
      "     |  \n",
      "     |      data = Data(x=x, edge_index=edge_index)\n",
      "     |      data.train_idx = torch.tensor([...], dtype=torch.long)\n",
      "     |      data.test_mask = torch.tensor([...], dtype=torch.bool)\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __apply__(self, item, func)\n",
      "     |  \n",
      "     |  __call__(self, *keys)\n",
      "     |      Iterates over all attributes :obj:`*keys` in the data, yielding\n",
      "     |      their attribute names and content.\n",
      "     |      If :obj:`*keys` is not given this method will iterative over all\n",
      "     |      present attributes.\n",
      "     |  \n",
      "     |  __cat_dim__(self, key, value)\n",
      "     |      Returns the dimension for which :obj:`value` of attribute\n",
      "     |      :obj:`key` will get concatenated when creating batches.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This method is for internal use only, and should only be overridden\n",
      "     |          if the batch concatenation process is corrupted for a specific data\n",
      "     |          attribute.\n",
      "     |  \n",
      "     |  __contains__(self, key)\n",
      "     |      Returns :obj:`True`, if the attribute :obj:`key` is present in the\n",
      "     |      data.\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |      Gets the data of the attribute :obj:`key`.\n",
      "     |  \n",
      "     |  __inc__(self, key, value)\n",
      "     |      Returns the incremental count to cumulatively increase the value\n",
      "     |      of the next attribute of :obj:`key` when creating batches.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This method is for internal use only, and should only be overridden\n",
      "     |          if the batch concatenation process is corrupted for a specific data\n",
      "     |          attribute.\n",
      "     |  \n",
      "     |  __init__(self, x=None, edge_index=None, edge_attr=None, y=None, pos=None, normal=None, face=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Iterates over all present attributes in the data, yielding their\n",
      "     |      attribute names and content.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Returns the number of all present attributes.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |      Sets the attribute :obj:`key` to :obj:`value`.\n",
      "     |  \n",
      "     |  apply(self, func, *keys)\n",
      "     |      Applies the function :obj:`func` to all tensor attributes\n",
      "     |      :obj:`*keys`. If :obj:`*keys` is not given, :obj:`func` is applied to\n",
      "     |      all present attributes.\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |  \n",
      "     |  coalesce(self)\n",
      "     |      \"Orders and removes duplicated entries from edge indices.\n",
      "     |  \n",
      "     |  contains_isolated_nodes(self)\n",
      "     |      Returns :obj:`True`, if the graph contains isolated nodes.\n",
      "     |  \n",
      "     |  contains_self_loops(self)\n",
      "     |      Returns :obj:`True`, if the graph contains self-loops.\n",
      "     |  \n",
      "     |  contiguous(self, *keys)\n",
      "     |      Ensures a contiguous memory layout for all attributes :obj:`*keys`.\n",
      "     |      If :obj:`*keys` is not given, all present attributes are ensured to\n",
      "     |      have a contiguous memory layout.\n",
      "     |  \n",
      "     |  cpu(self, *keys)\n",
      "     |      Copies all attributes :obj:`*keys` to CPU memory.\n",
      "     |      If :obj:`*keys` is not given, the conversion is applied to all present\n",
      "     |      attributes.\n",
      "     |  \n",
      "     |  cuda(self, device=None, non_blocking=False, *keys)\n",
      "     |      Copies all attributes :obj:`*keys` to CUDA memory.\n",
      "     |      If :obj:`*keys` is not given, the conversion is applied to all present\n",
      "     |      attributes.\n",
      "     |  \n",
      "     |  debug(self)\n",
      "     |  \n",
      "     |  is_coalesced(self)\n",
      "     |      Returns :obj:`True`, if edge indices are ordered and do not contain\n",
      "     |      duplicate entries.\n",
      "     |  \n",
      "     |  is_directed(self)\n",
      "     |      Returns :obj:`True`, if graph edges are directed.\n",
      "     |  \n",
      "     |  is_undirected(self)\n",
      "     |      Returns :obj:`True`, if graph edges are undirected.\n",
      "     |  \n",
      "     |  pin_memory(self, *keys)\n",
      "     |      Copies all attributes :obj:`*keys` to pinned memory.\n",
      "     |      If :obj:`*keys` is not given, the conversion is applied to all present\n",
      "     |      attributes.\n",
      "     |  \n",
      "     |  to(self, device, *keys, **kwargs)\n",
      "     |      Performs tensor dtype and/or device conversion to all attributes\n",
      "     |      :obj:`*keys`.\n",
      "     |      If :obj:`*keys` is not given, the conversion is applied to all present\n",
      "     |      attributes.\n",
      "     |  \n",
      "     |  to_dict(self)\n",
      "     |  \n",
      "     |  to_namedtuple(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_dict(dictionary) from builtins.type\n",
      "     |      Creates a data object from a python dictionary.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  keys\n",
      "     |      Returns all names of graph attributes.\n",
      "     |  \n",
      "     |  num_edge_features\n",
      "     |      Returns the number of features per edge in the graph.\n",
      "     |  \n",
      "     |  num_edges\n",
      "     |      Returns the number of edges in the graph.\n",
      "     |      For undirected graphs, this will return the number of bi-directional\n",
      "     |      edges, which is double the amount of unique edges.\n",
      "     |  \n",
      "     |  num_faces\n",
      "     |      Returns the number of faces in the mesh.\n",
      "     |  \n",
      "     |  num_features\n",
      "     |      Alias for :py:attr:`~num_node_features`.\n",
      "     |  \n",
      "     |  num_node_features\n",
      "     |      Returns the number of features per node in the graph.\n",
      "     |  \n",
      "     |  num_nodes\n",
      "     |      Returns or sets the number of nodes in the graph.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          The number of nodes in your data object is typically automatically\n",
      "     |          inferred, *e.g.*, when node features :obj:`x` are present.\n",
      "     |          In some cases however, a graph may only be given by its edge\n",
      "     |          indices :obj:`edge_index`.\n",
      "     |          PyTorch Geometric then *guesses* the number of nodes\n",
      "     |          according to :obj:`edge_index.max().item() + 1`, but in case there\n",
      "     |          exists isolated nodes, this number has not to be correct and can\n",
      "     |          therefore result in unexpected batch-wise behavior.\n",
      "     |          Thus, we recommend to set the number of nodes in your data object\n",
      "     |          explicitly via :obj:`data.num_nodes = ...`.\n",
      "     |          You will be given a warning that requests you to do so.\n",
      "    \n",
      "    class DataListLoader(torch.utils.data.dataloader.DataLoader)\n",
      "     |  DataListLoader(dataset, batch_size=1, shuffle=False, **kwargs)\n",
      "     |  \n",
      "     |  Data loader which merges data objects from a\n",
      "     |  :class:`torch_geometric.data.dataset` to a python list.\n",
      "     |  \n",
      "     |  .. note::\n",
      "     |  \n",
      "     |      This data loader should be used for multi-gpu support via\n",
      "     |      :class:`torch_geometric.nn.DataParallel`.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      dataset (Dataset): The dataset from which to load the data.\n",
      "     |      batch_size (int, optional): How many samples per batch to load.\n",
      "     |          (default: :obj:`1`)\n",
      "     |      shuffle (bool, optional): If set to :obj:`True`, the data will be\n",
      "     |          reshuffled at every epoch (default: :obj:`False`)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DataListLoader\n",
      "     |      torch.utils.data.dataloader.DataLoader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dataset, batch_size=1, shuffle=False, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __setattr__(self, attr, val)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  multiprocessing_context\n",
      "    \n",
      "    class DataLoader(torch.utils.data.dataloader.DataLoader)\n",
      "     |  DataLoader(dataset, batch_size=1, shuffle=False, follow_batch=[], exclude_keys=[], **kwargs)\n",
      "     |  \n",
      "     |  Data loader which merges data objects from a\n",
      "     |  :class:`torch_geometric.data.dataset` to a mini-batch.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      dataset (Dataset): The dataset from which to load the data.\n",
      "     |      batch_size (int, optional): How many samples per batch to load.\n",
      "     |          (default: :obj:`1`)\n",
      "     |      shuffle (bool, optional): If set to :obj:`True`, the data will be\n",
      "     |          reshuffled at every epoch. (default: :obj:`False`)\n",
      "     |      follow_batch (list or tuple, optional): Creates assignment batch\n",
      "     |          vectors for each key in the list. (default: :obj:`[]`)\n",
      "     |      exclude_keys (list or tuple, optional): Will exclude each key in the\n",
      "     |          list. (default: :obj:`[]`)\n",
      "     |      **kwargs (optional): Additional arguments of\n",
      "     |          :class:`torch.utils.data.DataLoader`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DataLoader\n",
      "     |      torch.utils.data.dataloader.DataLoader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dataset, batch_size=1, shuffle=False, follow_batch=[], exclude_keys=[], **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __setattr__(self, attr, val)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  multiprocessing_context\n",
      "    \n",
      "    class Dataset(torch.utils.data.dataset.Dataset)\n",
      "     |  Dataset(root=None, transform=None, pre_transform=None, pre_filter=None)\n",
      "     |  \n",
      "     |  Dataset base class for creating graph datasets.\n",
      "     |  See `here <https://pytorch-geometric.readthedocs.io/en/latest/notes/\n",
      "     |  create_dataset.html>`__ for the accompanying tutorial.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string, optional): Root directory where the dataset should be\n",
      "     |          saved. (optional: :obj:`None`)\n",
      "     |      transform (callable, optional): A function/transform that takes in an\n",
      "     |          :obj:`torch_geometric.data.Data` object and returns a transformed\n",
      "     |          version. The data object will be transformed before every access.\n",
      "     |          (default: :obj:`None`)\n",
      "     |      pre_transform (callable, optional): A function/transform that takes in\n",
      "     |          an :obj:`torch_geometric.data.Data` object and returns a\n",
      "     |          transformed version. The data object will be transformed before\n",
      "     |          being saved to disk. (default: :obj:`None`)\n",
      "     |      pre_filter (callable, optional): A function that takes in an\n",
      "     |          :obj:`torch_geometric.data.Data` object and returns a boolean\n",
      "     |          value, indicating whether the data object should be included in the\n",
      "     |          final dataset. (default: :obj:`None`)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Dataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx)\n",
      "     |      Gets the data object at index :obj:`idx` and transforms it (in case\n",
      "     |      a :obj:`self.transform` is given).\n",
      "     |      In case :obj:`idx` is a slicing object, *e.g.*, :obj:`[2:5]`, a list, a\n",
      "     |      tuple, a  LongTensor or a BoolTensor, will return a subset of the\n",
      "     |      dataset at the specified indices.\n",
      "     |  \n",
      "     |  __init__(self, root=None, transform=None, pre_transform=None, pre_filter=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      The number of examples in the dataset.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  download(self)\n",
      "     |      Downloads the dataset to the :obj:`self.raw_dir` folder.\n",
      "     |  \n",
      "     |  get(self, idx)\n",
      "     |      Gets the data object at index :obj:`idx`.\n",
      "     |  \n",
      "     |  index_select(self, idx)\n",
      "     |  \n",
      "     |  indices(self)\n",
      "     |  \n",
      "     |  len(self)\n",
      "     |  \n",
      "     |  process(self)\n",
      "     |      Processes the dataset to the :obj:`self.processed_dir` folder.\n",
      "     |  \n",
      "     |  shuffle(self, return_perm=False)\n",
      "     |      Randomly shuffles the examples in the dataset.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          return_perm (bool, optional): If set to :obj:`True`, will\n",
      "     |              additionally return the random permutation used to shuffle the\n",
      "     |              dataset. (default: :obj:`False`)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  num_edge_features\n",
      "     |      Returns the number of features per edge in the dataset.\n",
      "     |  \n",
      "     |  num_features\n",
      "     |      Alias for :py:attr:`~num_node_features`.\n",
      "     |  \n",
      "     |  num_node_features\n",
      "     |      Returns the number of features per node in the dataset.\n",
      "     |  \n",
      "     |  processed_dir\n",
      "     |  \n",
      "     |  processed_file_names\n",
      "     |      The name of the files to find in the :obj:`self.processed_dir`\n",
      "     |      folder in order to skip the processing.\n",
      "     |  \n",
      "     |  processed_paths\n",
      "     |      The filepaths to find in the :obj:`self.processed_dir`\n",
      "     |      folder in order to skip the processing.\n",
      "     |  \n",
      "     |  raw_dir\n",
      "     |  \n",
      "     |  raw_file_names\n",
      "     |      The name of the files to find in the :obj:`self.raw_dir` folder in\n",
      "     |      order to skip the download.\n",
      "     |  \n",
      "     |  raw_paths\n",
      "     |      The filepaths to find in order to skip the download.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class DenseDataLoader(torch.utils.data.dataloader.DataLoader)\n",
      "     |  DenseDataLoader(dataset, batch_size=1, shuffle=False, **kwargs)\n",
      "     |  \n",
      "     |  Data loader which merges data objects from a\n",
      "     |  :class:`torch_geometric.data.dataset` to a mini-batch.\n",
      "     |  \n",
      "     |  .. note::\n",
      "     |  \n",
      "     |      To make use of this data loader, all graphs in the dataset needs to\n",
      "     |      have the same shape for each its attributes.\n",
      "     |      Therefore, this data loader should only be used when working with\n",
      "     |      *dense* adjacency matrices.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      dataset (Dataset): The dataset from which to load the data.\n",
      "     |      batch_size (int, optional): How many samples per batch to load.\n",
      "     |          (default: :obj:`1`)\n",
      "     |      shuffle (bool, optional): If set to :obj:`True`, the data will be\n",
      "     |          reshuffled at every epoch (default: :obj:`False`)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DenseDataLoader\n",
      "     |      torch.utils.data.dataloader.DataLoader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dataset, batch_size=1, shuffle=False, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __setattr__(self, attr, val)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  multiprocessing_context\n",
      "    \n",
      "    class GraphSAINTEdgeSampler(GraphSAINTSampler)\n",
      "     |  GraphSAINTEdgeSampler(data, batch_size: int, num_steps: int = 1, sample_coverage: int = 0, save_dir: Union[str, NoneType] = None, log: bool = True, **kwargs)\n",
      "     |  \n",
      "     |  The GraphSAINT edge sampler class (see\n",
      "     |  :class:`torch_geometric.data.GraphSAINTSampler`).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GraphSAINTEdgeSampler\n",
      "     |      GraphSAINTSampler\n",
      "     |      torch.utils.data.dataloader.DataLoader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __sample_nodes__(self, batch_size)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from GraphSAINTSampler:\n",
      "     |  \n",
      "     |  __collate__(self, data_list)\n",
      "     |  \n",
      "     |  __compute_norm__(self)\n",
      "     |  \n",
      "     |  __getitem__(self, idx)\n",
      "     |  \n",
      "     |  __init__(self, data, batch_size: int, num_steps: int = 1, sample_coverage: int = 0, save_dir: Union[str, NoneType] = None, log: bool = True, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from GraphSAINTSampler:\n",
      "     |  \n",
      "     |  __filename__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __setattr__(self, attr, val)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  multiprocessing_context\n",
      "    \n",
      "    class GraphSAINTNodeSampler(GraphSAINTSampler)\n",
      "     |  GraphSAINTNodeSampler(data, batch_size: int, num_steps: int = 1, sample_coverage: int = 0, save_dir: Union[str, NoneType] = None, log: bool = True, **kwargs)\n",
      "     |  \n",
      "     |  The GraphSAINT node sampler class (see\n",
      "     |  :class:`torch_geometric.data.GraphSAINTSampler`).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GraphSAINTNodeSampler\n",
      "     |      GraphSAINTSampler\n",
      "     |      torch.utils.data.dataloader.DataLoader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __sample_nodes__(self, batch_size)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from GraphSAINTSampler:\n",
      "     |  \n",
      "     |  __collate__(self, data_list)\n",
      "     |  \n",
      "     |  __compute_norm__(self)\n",
      "     |  \n",
      "     |  __getitem__(self, idx)\n",
      "     |  \n",
      "     |  __init__(self, data, batch_size: int, num_steps: int = 1, sample_coverage: int = 0, save_dir: Union[str, NoneType] = None, log: bool = True, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from GraphSAINTSampler:\n",
      "     |  \n",
      "     |  __filename__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __setattr__(self, attr, val)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  multiprocessing_context\n",
      "    \n",
      "    class GraphSAINTRandomWalkSampler(GraphSAINTSampler)\n",
      "     |  GraphSAINTRandomWalkSampler(data, batch_size: int, walk_length: int, num_steps: int = 1, sample_coverage: int = 0, save_dir: Union[str, NoneType] = None, log: bool = True, **kwargs)\n",
      "     |  \n",
      "     |  The GraphSAINT random walk sampler class (see\n",
      "     |  :class:`torch_geometric.data.GraphSAINTSampler`).\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      walk_length (int): The length of each random walk.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GraphSAINTRandomWalkSampler\n",
      "     |      GraphSAINTSampler\n",
      "     |      torch.utils.data.dataloader.DataLoader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, data, batch_size: int, walk_length: int, num_steps: int = 1, sample_coverage: int = 0, save_dir: Union[str, NoneType] = None, log: bool = True, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __sample_nodes__(self, batch_size)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __filename__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from GraphSAINTSampler:\n",
      "     |  \n",
      "     |  __collate__(self, data_list)\n",
      "     |  \n",
      "     |  __compute_norm__(self)\n",
      "     |  \n",
      "     |  __getitem__(self, idx)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __setattr__(self, attr, val)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  multiprocessing_context\n",
      "    \n",
      "    class GraphSAINTSampler(torch.utils.data.dataloader.DataLoader)\n",
      "     |  GraphSAINTSampler(data, batch_size: int, num_steps: int = 1, sample_coverage: int = 0, save_dir: Union[str, NoneType] = None, log: bool = True, **kwargs)\n",
      "     |  \n",
      "     |  The GraphSAINT sampler base class from the `\"GraphSAINT: Graph\n",
      "     |  Sampling Based Inductive Learning Method\"\n",
      "     |  <https://arxiv.org/abs/1907.04931>`_ paper.\n",
      "     |  Given a graph in a :obj:`data` object, this class samples nodes and\n",
      "     |  constructs subgraphs that can be processed in a mini-batch fashion.\n",
      "     |  Normalization coefficients for each mini-batch are given via\n",
      "     |  :obj:`node_norm` and :obj:`edge_norm` data attributes.\n",
      "     |  \n",
      "     |  .. note::\n",
      "     |  \n",
      "     |      See :class:`torch_geometric.data.GraphSAINTNodeSampler`,\n",
      "     |      :class:`torch_geometric.data.GraphSAINTEdgeSampler` and\n",
      "     |      :class:`torch_geometric.data.GraphSAINTRandomWalkSampler` for\n",
      "     |      currently supported samplers.\n",
      "     |      For an example of using GraphSAINT sampling, see\n",
      "     |      `examples/graph_saint.py <https://github.com/rusty1s/pytorch_geometric/\n",
      "     |      blob/master/examples/graph_saint.py>`_.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      data (torch_geometric.data.Data): The graph data object.\n",
      "     |      batch_size (int): The approximate number of samples per batch.\n",
      "     |      num_steps (int, optional): The number of iterations per epoch.\n",
      "     |          (default: :obj:`1`)\n",
      "     |      sample_coverage (int): How many samples per node should be used to\n",
      "     |          compute normalization statistics. (default: :obj:`0`)\n",
      "     |      save_dir (string, optional): If set, will save normalization\n",
      "     |          statistics to the :obj:`save_dir` directory for faster re-use.\n",
      "     |          (default: :obj:`None`)\n",
      "     |      log (bool, optional): If set to :obj:`False`, will not log any\n",
      "     |          pre-processing progress. (default: :obj:`True`)\n",
      "     |      **kwargs (optional): Additional arguments of\n",
      "     |          :class:`torch.utils.data.DataLoader`, such as :obj:`batch_size` or\n",
      "     |          :obj:`num_workers`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GraphSAINTSampler\n",
      "     |      torch.utils.data.dataloader.DataLoader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __collate__(self, data_list)\n",
      "     |  \n",
      "     |  __compute_norm__(self)\n",
      "     |  \n",
      "     |  __getitem__(self, idx)\n",
      "     |  \n",
      "     |  __init__(self, data, batch_size: int, num_steps: int = 1, sample_coverage: int = 0, save_dir: Union[str, NoneType] = None, log: bool = True, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __sample_nodes__(self, batch_size)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __filename__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __setattr__(self, attr, val)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  multiprocessing_context\n",
      "    \n",
      "    class InMemoryDataset(torch_geometric.data.dataset.Dataset)\n",
      "     |  InMemoryDataset(root=None, transform=None, pre_transform=None, pre_filter=None)\n",
      "     |  \n",
      "     |  Dataset base class for creating graph datasets which fit completely\n",
      "     |  into CPU memory.\n",
      "     |  See `here <https://pytorch-geometric.readthedocs.io/en/latest/notes/\n",
      "     |  create_dataset.html#creating-in-memory-datasets>`__ for the accompanying\n",
      "     |  tutorial.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string, optional): Root directory where the dataset should be\n",
      "     |          saved. (default: :obj:`None`)\n",
      "     |      transform (callable, optional): A function/transform that takes in an\n",
      "     |          :obj:`torch_geometric.data.Data` object and returns a transformed\n",
      "     |          version. The data object will be transformed before every access.\n",
      "     |          (default: :obj:`None`)\n",
      "     |      pre_transform (callable, optional): A function/transform that takes in\n",
      "     |          an :obj:`torch_geometric.data.Data` object and returns a\n",
      "     |          transformed version. The data object will be transformed before\n",
      "     |          being saved to disk. (default: :obj:`None`)\n",
      "     |      pre_filter (callable, optional): A function that takes in an\n",
      "     |          :obj:`torch_geometric.data.Data` object and returns a boolean\n",
      "     |          value, indicating whether the data object should be included in the\n",
      "     |          final dataset. (default: :obj:`None`)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      InMemoryDataset\n",
      "     |      torch_geometric.data.dataset.Dataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root=None, transform=None, pre_transform=None, pre_filter=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  copy(self, idx=None)\n",
      "     |  \n",
      "     |  download(self)\n",
      "     |      Downloads the dataset to the :obj:`self.raw_dir` folder.\n",
      "     |  \n",
      "     |  get(self, idx)\n",
      "     |      Gets the data object at index :obj:`idx`.\n",
      "     |  \n",
      "     |  len(self)\n",
      "     |  \n",
      "     |  process(self)\n",
      "     |      Processes the dataset to the :obj:`self.processed_dir` folder.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  collate(data_list)\n",
      "     |      Collates a python list of data objects to the internal storage\n",
      "     |      format of :class:`torch_geometric.data.InMemoryDataset`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  num_classes\n",
      "     |      The number of classes in the dataset.\n",
      "     |  \n",
      "     |  processed_file_names\n",
      "     |      The name of the files to find in the :obj:`self.processed_dir`\n",
      "     |      folder in order to skip the processing.\n",
      "     |  \n",
      "     |  raw_file_names\n",
      "     |      The name of the files to find in the :obj:`self.raw_dir` folder in\n",
      "     |      order to skip the download.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch_geometric.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __getitem__(self, idx)\n",
      "     |      Gets the data object at index :obj:`idx` and transforms it (in case\n",
      "     |      a :obj:`self.transform` is given).\n",
      "     |      In case :obj:`idx` is a slicing object, *e.g.*, :obj:`[2:5]`, a list, a\n",
      "     |      tuple, a  LongTensor or a BoolTensor, will return a subset of the\n",
      "     |      dataset at the specified indices.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      The number of examples in the dataset.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  index_select(self, idx)\n",
      "     |  \n",
      "     |  indices(self)\n",
      "     |  \n",
      "     |  shuffle(self, return_perm=False)\n",
      "     |      Randomly shuffles the examples in the dataset.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          return_perm (bool, optional): If set to :obj:`True`, will\n",
      "     |              additionally return the random permutation used to shuffle the\n",
      "     |              dataset. (default: :obj:`False`)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch_geometric.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  num_edge_features\n",
      "     |      Returns the number of features per edge in the dataset.\n",
      "     |  \n",
      "     |  num_features\n",
      "     |      Alias for :py:attr:`~num_node_features`.\n",
      "     |  \n",
      "     |  num_node_features\n",
      "     |      Returns the number of features per node in the dataset.\n",
      "     |  \n",
      "     |  processed_dir\n",
      "     |  \n",
      "     |  processed_paths\n",
      "     |      The filepaths to find in the :obj:`self.processed_dir`\n",
      "     |      folder in order to skip the processing.\n",
      "     |  \n",
      "     |  raw_dir\n",
      "     |  \n",
      "     |  raw_paths\n",
      "     |      The filepaths to find in order to skip the download.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class NeighborSampler(torch.utils.data.dataloader.DataLoader)\n",
      "     |  NeighborSampler(edge_index: Union[torch.Tensor, torch_sparse.tensor.SparseTensor], sizes: List[int], node_idx: Union[torch.Tensor, NoneType] = None, num_nodes: Union[int, NoneType] = None, return_e_id: bool = True, transform: Callable = None, **kwargs)\n",
      "     |  \n",
      "     |  The neighbor sampler from the `\"Inductive Representation Learning on\n",
      "     |  Large Graphs\" <https://arxiv.org/abs/1706.02216>`_ paper, which allows\n",
      "     |  for mini-batch training of GNNs on large-scale graphs where full-batch\n",
      "     |  training is not feasible.\n",
      "     |  \n",
      "     |  Given a GNN with :math:`L` layers and a specific mini-batch of nodes\n",
      "     |  :obj:`node_idx` for which we want to compute embeddings, this module\n",
      "     |  iteratively samples neighbors and constructs bipartite graphs that simulate\n",
      "     |  the actual computation flow of GNNs.\n",
      "     |  \n",
      "     |  More specifically, :obj:`sizes` denotes how much neighbors we want to\n",
      "     |  sample for each node in each layer.\n",
      "     |  This module then takes in these :obj:`sizes` and iteratively samples\n",
      "     |  :obj:`sizes[l]` for each node involved in layer :obj:`l`.\n",
      "     |  In the next layer, sampling is repeated for the union of nodes that were\n",
      "     |  already encountered.\n",
      "     |  The actual computation graphs are then returned in reverse-mode, meaning\n",
      "     |  that we pass messages from a larger set of nodes to a smaller one, until we\n",
      "     |  reach the nodes for which we originally wanted to compute embeddings.\n",
      "     |  \n",
      "     |  Hence, an item returned by :class:`NeighborSampler` holds the current\n",
      "     |  :obj:`batch_size`, the IDs :obj:`n_id` of all nodes involved in the\n",
      "     |  computation, and a list of bipartite graph objects via the tuple\n",
      "     |  :obj:`(edge_index, e_id, size)`, where :obj:`edge_index` represents the\n",
      "     |  bipartite edges between source and target nodes, :obj:`e_id` denotes the\n",
      "     |  IDs of original edges in the full graph, and :obj:`size` holds the shape\n",
      "     |  of the bipartite graph.\n",
      "     |  For each bipartite graph, target nodes are also included at the beginning\n",
      "     |  of the list of source nodes so that one can easily apply skip-connections\n",
      "     |  or add self-loops.\n",
      "     |  \n",
      "     |  .. note::\n",
      "     |  \n",
      "     |      For an example of using :obj:`NeighborSampler`, see\n",
      "     |      `examples/reddit.py\n",
      "     |      <https://github.com/rusty1s/pytorch_geometric/blob/master/examples/\n",
      "     |      reddit.py>`_ or\n",
      "     |      `examples/ogbn_products_sage.py\n",
      "     |      <https://github.com/rusty1s/pytorch_geometric/blob/master/examples/\n",
      "     |      ogbn_products_sage.py>`_.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      edge_index (Tensor or SparseTensor): A :obj:`torch.LongTensor` or a\n",
      "     |          :obj:`torch_sparse.SparseTensor` that defines the underlying graph\n",
      "     |          connectivity/message passing flow.\n",
      "     |          :obj:`edge_index` holds the indices of a (sparse) symmetric\n",
      "     |          adjacency matrix.\n",
      "     |          If :obj:`edge_index` is of type :obj:`torch.LongTensor`, its shape\n",
      "     |          must be defined as :obj:`[2, num_edges]`, where messages from nodes\n",
      "     |          :obj:`edge_index[0]` are sent to nodes in :obj:`edge_index[1]`\n",
      "     |          (in case :obj:`flow=\"source_to_target\"`).\n",
      "     |          If :obj:`edge_index` is of type :obj:`torch_sparse.SparseTensor`,\n",
      "     |          its sparse indices :obj:`(row, col)` should relate to\n",
      "     |          :obj:`row = edge_index[1]` and :obj:`col = edge_index[0]`.\n",
      "     |          The major difference between both formats is that we need to input\n",
      "     |          the *transposed* sparse adjacency matrix.\n",
      "     |      sizes ([int]): The number of neighbors to sample for each node in each\n",
      "     |          layer. If set to :obj:`sizes[l] = -1`, all neighbors are included\n",
      "     |          in layer :obj:`l`.\n",
      "     |      node_idx (LongTensor, optional): The nodes that should be considered\n",
      "     |          for creating mini-batches. If set to :obj:`None`, all nodes will be\n",
      "     |          considered.\n",
      "     |      num_nodes (int, optional): The number of nodes in the graph.\n",
      "     |          (default: :obj:`None`)\n",
      "     |      return_e_id (bool, optional): If set to :obj:`False`, will not return\n",
      "     |          original edge indices of sampled edges. This is only useful in case\n",
      "     |          when operating on graphs without edge features to save memory.\n",
      "     |          (default: :obj:`True`)\n",
      "     |      transform (callable, optional): A function/transform that takes in\n",
      "     |          an a sampled mini-batch and returns a transformed version.\n",
      "     |          (default: :obj:`None`)\n",
      "     |      **kwargs (optional): Additional arguments of\n",
      "     |          :class:`torch.utils.data.DataLoader`, such as :obj:`batch_size`,\n",
      "     |          :obj:`shuffle`, :obj:`drop_last` or :obj:`num_workers`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NeighborSampler\n",
      "     |      torch.utils.data.dataloader.DataLoader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, edge_index: Union[torch.Tensor, torch_sparse.tensor.SparseTensor], sizes: List[int], node_idx: Union[torch.Tensor, NoneType] = None, num_nodes: Union[int, NoneType] = None, return_e_id: bool = True, transform: Callable = None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  sample(self, batch)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __setattr__(self, attr, val)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  multiprocessing_context\n",
      "    \n",
      "    class RandomNodeSampler(torch.utils.data.dataloader.DataLoader)\n",
      "     |  RandomNodeSampler(data, num_parts: int, shuffle: bool = False, **kwargs)\n",
      "     |  \n",
      "     |  A data loader that randomly samples nodes within a graph and returns\n",
      "     |  their induced subgraph.\n",
      "     |  \n",
      "     |  .. note::\n",
      "     |  \n",
      "     |      For an example of using :obj:`RandomNodeSampler`, see\n",
      "     |      `examples/ogbn_proteins_deepgcn.py\n",
      "     |      <https://github.com/rusty1s/pytorch_geometric/blob/master/examples/\n",
      "     |      ogbn_proteins_deepgcn.py>`_.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      data (torch_geometric.data.Data): The graph data object.\n",
      "     |      num_parts (int): The number of partitions.\n",
      "     |      shuffle (bool, optional): If set to :obj:`True`, the data is reshuffled\n",
      "     |          at every epoch (default: :obj:`False`).\n",
      "     |      **kwargs (optional): Additional arguments of\n",
      "     |          :class:`torch.utils.data.DataLoader`, such as :obj:`num_workers`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RandomNodeSampler\n",
      "     |      torch.utils.data.dataloader.DataLoader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __collate__(self, node_idx)\n",
      "     |  \n",
      "     |  __getitem__(self, idx)\n",
      "     |  \n",
      "     |  __init__(self, data, num_parts: int, shuffle: bool = False, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __setattr__(self, attr, val)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  multiprocessing_context\n",
      "    \n",
      "    class ShaDowKHopSampler(torch.utils.data.dataloader.DataLoader)\n",
      "     |  ShaDowKHopSampler(data: torch_geometric.data.data.Data, depth: int, num_neighbors: int, node_idx: Union[torch.Tensor, NoneType] = None, replace: bool = False, **kwargs)\n",
      "     |  \n",
      "     |  The ShaDow :math:`k`-hop sampler from the `\"Deep Graph Neural Networks\n",
      "     |  with Shallow Subgraph Samplers\" <https://arxiv.org/abs/2012.01380>`_ paper.\n",
      "     |  Given a graph in a :obj:`data` object, the sampler will create shallow,\n",
      "     |  localized subgraphs.\n",
      "     |  A deep GNN on this local graph then smooths the informative local signals.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      data (torch_geometric.data.Data): The graph data object.\n",
      "     |      depth (int): The depth/number of hops of the localized subgraph.\n",
      "     |      num_neighbors (int): The number of neighbors to sample for each node in\n",
      "     |          each hop.\n",
      "     |      node_idx (LongTensor or BoolTensor, optional): The nodes that should be\n",
      "     |          considered for creating mini-batches.\n",
      "     |          If set to :obj:`None`, all nodes will be\n",
      "     |          considered.\n",
      "     |      replace (bool, optional): If set to :obj:`True`, will sample neighbors\n",
      "     |          with replacement. (default: :obj:`False`)\n",
      "     |      **kwargs (optional): Additional arguments of\n",
      "     |          :class:`torch.utils.data.DataLoader`, such as :obj:`batch_size` or\n",
      "     |          :obj:`num_workers`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ShaDowKHopSampler\n",
      "     |      torch.utils.data.dataloader.DataLoader\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __collate__(self, n_id)\n",
      "     |  \n",
      "     |  __init__(self, data: torch_geometric.data.data.Data, depth: int, num_neighbors: int, node_idx: Union[torch.Tensor, NoneType] = None, replace: bool = False, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __setattr__(self, attr, val)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataloader.DataLoader:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  multiprocessing_context\n",
      "    \n",
      "    class TemporalData(builtins.object)\n",
      "     |  TemporalData(src=None, dst=None, t=None, msg=None, y=None, **kwargs)\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __apply__(self, item, func)\n",
      "     |  \n",
      "     |  __call__(self, *keys)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  __cat_dim__(self, key, value)\n",
      "     |  \n",
      "     |  __contains__(self, key)\n",
      "     |  \n",
      "     |  __getitem__(self, idx)\n",
      "     |  \n",
      "     |  __inc__(self, key, value)\n",
      "     |  \n",
      "     |  __init__(self, src=None, dst=None, t=None, msg=None, y=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |      Sets the attribute :obj:`key` to :obj:`value`.\n",
      "     |  \n",
      "     |  apply(self, func, *keys)\n",
      "     |      Applies the function :obj:`func` to all tensor attributes\n",
      "     |      :obj:`*keys`. If :obj:`*keys` is not given, :obj:`func` is applied to\n",
      "     |      all present attributes.\n",
      "     |  \n",
      "     |  seq_batches(self, batch_size)\n",
      "     |  \n",
      "     |  to(self, device, *keys, **kwargs)\n",
      "     |  \n",
      "     |  train_val_test_split(self, val_ratio=0.15, test_ratio=0.15)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  keys\n",
      "     |  \n",
      "     |  num_events\n",
      "     |  \n",
      "     |  num_nodes\n",
      "\n",
      "FUNCTIONS\n",
      "    download_url(url, folder, log=True)\n",
      "        Downloads the content of an URL to a specific folder.\n",
      "        \n",
      "        Args:\n",
      "            url (string): The url.\n",
      "            folder (string): The folder.\n",
      "            log (bool, optional): If :obj:`False`, will not print anything to the\n",
      "                console. (default: :obj:`True`)\n",
      "    \n",
      "    extract_bz2(path, folder, log=True)\n",
      "    \n",
      "    extract_gz(path, folder, log=True)\n",
      "    \n",
      "    extract_tar(path, folder, mode='r:gz', log=True)\n",
      "        Extracts a tar archive to a specific folder.\n",
      "        \n",
      "        Args:\n",
      "            path (string): The path to the tar archive.\n",
      "            folder (string): The folder.\n",
      "            mode (string, optional): The compression mode. (default: :obj:`\"r:gz\"`)\n",
      "            log (bool, optional): If :obj:`False`, will not print anything to the\n",
      "                console. (default: :obj:`True`)\n",
      "    \n",
      "    extract_zip(path, folder, log=True)\n",
      "        Extracts a zip archive to a specific folder.\n",
      "        \n",
      "        Args:\n",
      "            path (string): The path to the tar archive.\n",
      "            folder (string): The folder.\n",
      "            log (bool, optional): If :obj:`False`, will not print anything to the\n",
      "                console. (default: :obj:`True`)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['Data', 'TemporalData', 'Batch', 'Dataset', 'InMemoryDatase...\n",
      "\n",
      "FILE\n",
      "    /home/pellegrini/.miniconda3/envs/lafexp/lib/python3.7/site-packages/torch_geometric/data/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KarateClub',\n",
       " 'TUDataset',\n",
       " 'GNNBenchmarkDataset',\n",
       " 'Planetoid',\n",
       " 'NELL',\n",
       " 'CitationFull',\n",
       " 'CoraFull',\n",
       " 'Coauthor',\n",
       " 'Amazon',\n",
       " 'PPI',\n",
       " 'Reddit',\n",
       " 'Reddit2',\n",
       " 'Flickr',\n",
       " 'Yelp',\n",
       " 'QM7b',\n",
       " 'QM9',\n",
       " 'ZINC',\n",
       " 'MoleculeNet',\n",
       " 'Entities',\n",
       " 'GEDDataset',\n",
       " 'MNISTSuperpixels',\n",
       " 'FAUST',\n",
       " 'DynamicFAUST',\n",
       " 'ShapeNet',\n",
       " 'ModelNet',\n",
       " 'CoMA',\n",
       " 'SHREC2016',\n",
       " 'TOSCA',\n",
       " 'PCPNetDataset',\n",
       " 'S3DIS',\n",
       " 'GeometricShapes',\n",
       " 'BitcoinOTC',\n",
       " 'ICEWS18',\n",
       " 'GDELT',\n",
       " 'DBP15K',\n",
       " 'WILLOWObjectClass',\n",
       " 'PascalVOCKeypoints',\n",
       " 'PascalPF',\n",
       " 'SNAPDataset',\n",
       " 'SuiteSparseMatrixCollection',\n",
       " 'TrackMLParticleTrackingDataset',\n",
       " 'AMiner',\n",
       " 'WordNet18',\n",
       " 'WordNet18RR',\n",
       " 'WikiCS',\n",
       " 'WebKB',\n",
       " 'WikipediaNetwork',\n",
       " 'Actor',\n",
       " 'JODIEDataset',\n",
       " 'MixHopSyntheticDataset']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.__all__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cora = datasets.CoraFull(root='./data', transform=transforms.NormalizeFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__data_list__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__indices__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_download',\n",
       " '_process',\n",
       " 'collate',\n",
       " 'copy',\n",
       " 'data',\n",
       " 'download',\n",
       " 'get',\n",
       " 'index_select',\n",
       " 'indices',\n",
       " 'len',\n",
       " 'name',\n",
       " 'num_classes',\n",
       " 'num_edge_features',\n",
       " 'num_features',\n",
       " 'num_node_features',\n",
       " 'pre_filter',\n",
       " 'pre_transform',\n",
       " 'process',\n",
       " 'processed_dir',\n",
       " 'processed_file_names',\n",
       " 'processed_paths',\n",
       " 'raw_dir',\n",
       " 'raw_file_names',\n",
       " 'raw_paths',\n",
       " 'root',\n",
       " 'shuffle',\n",
       " 'slices',\n",
       " 'transform',\n",
       " 'url']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(cora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 126842], x=[19793, 8710], y=[19793])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__apply__',\n",
       " '__call__',\n",
       " '__cat_dim__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__inc__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'apply',\n",
       " 'clone',\n",
       " 'coalesce',\n",
       " 'contains_isolated_nodes',\n",
       " 'contains_self_loops',\n",
       " 'contiguous',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'debug',\n",
       " 'edge_attr',\n",
       " 'edge_index',\n",
       " 'face',\n",
       " 'from_dict',\n",
       " 'is_coalesced',\n",
       " 'is_directed',\n",
       " 'is_undirected',\n",
       " 'keys',\n",
       " 'normal',\n",
       " 'num_edge_features',\n",
       " 'num_edges',\n",
       " 'num_faces',\n",
       " 'num_features',\n",
       " 'num_node_features',\n",
       " 'num_nodes',\n",
       " 'pin_memory',\n",
       " 'pos',\n",
       " 'to',\n",
       " 'to_dict',\n",
       " 'to_namedtuple',\n",
       " 'x',\n",
       " 'y']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(cora.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora.data.num_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "zinc = datasets.ZINC(root=\"./data\", transform=transforms.NormalizeFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220011"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zinc.data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aids = datasets.TUDataset(root=\"./data\", name=\"AIDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__data_list__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__indices__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_download',\n",
       " '_process',\n",
       " 'cleaned',\n",
       " 'cleaned_url',\n",
       " 'collate',\n",
       " 'copy',\n",
       " 'data',\n",
       " 'download',\n",
       " 'get',\n",
       " 'index_select',\n",
       " 'indices',\n",
       " 'len',\n",
       " 'name',\n",
       " 'num_classes',\n",
       " 'num_edge_attributes',\n",
       " 'num_edge_features',\n",
       " 'num_edge_labels',\n",
       " 'num_features',\n",
       " 'num_node_attributes',\n",
       " 'num_node_features',\n",
       " 'num_node_labels',\n",
       " 'pre_filter',\n",
       " 'pre_transform',\n",
       " 'process',\n",
       " 'processed_dir',\n",
       " 'processed_file_names',\n",
       " 'processed_paths',\n",
       " 'raw_dir',\n",
       " 'raw_file_names',\n",
       " 'raw_paths',\n",
       " 'root',\n",
       " 'shuffle',\n",
       " 'slices',\n",
       " 'transform',\n",
       " 'url']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(aids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aids.num_edge_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[106, 3], edge_index=[2, 106], x=[47, 38], y=[1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aids[0].edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch_geometric.data.batch' from '/home/pellegrini/.miniconda3/envs/lafexp/lib/python3.7/site-packages/torch_geometric/data/batch.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch_geometric.data.cluster' from '/home/pellegrini/.miniconda3/envs/lafexp/lib/python3.7/site-packages/torch_geometric/data/cluster.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch_geometric.data.sampler' from '/home/pellegrini/.miniconda3/envs/lafexp/lib/python3.7/site-packages/torch_geometric/data/sampler.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing METIS partitioning...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Not compiled with METIS support",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-675687ed7d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClusterData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/lafexp/lib/python3.7/site-packages/torch_geometric/data/cluster.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, num_parts, recursive, save_dir, log)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 sparse_sizes=(N, N))\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msave_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/lafexp/lib/python3.7/site-packages/torch_sparse/metis.py\u001b[0m in \u001b[0;36mpartition\u001b[0;34m(src, num_parts, recursive, weighted)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     cluster = torch.ops.torch_sparse.partition(rowptr, col, value, num_parts,\n\u001b[0;32m---> 45\u001b[0;31m                                                recursive)\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mcluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Not compiled with METIS support"
     ]
    }
   ],
   "source": [
    "cluster = data.ClusterData(cora.data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cora.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('edge_index', tensor([[    0,     0,     0,  ..., 19791, 19791, 19792],\n",
      "        [ 1227,  4021,  4056,  ...,  5100, 10850,  2947]]))\n",
      "('x', tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]))\n",
      "('y', tensor([ 0,  0,  0,  ..., 52, 59, 55]))\n"
     ]
    }
   ],
   "source": [
    "for i in cora.data:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aids.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('edge_attr', tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.]]))\n",
      "('edge_index', tensor([[ 0,  0,  1,  ...,  9, 10, 10],\n",
      "        [ 1,  5,  0,  ..., 10,  6,  9]]))\n",
      "('x', tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]]))\n",
      "('y', tensor([0, 1, 1,  ..., 0, 0, 1]))\n"
     ]
    }
   ],
   "source": [
    "for i in aids.data:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for i in range(10):\n",
    "    d.append(aids[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(edge_attr=[106, 3], edge_index=[2, 106], x=[47, 38], y=[1]),\n",
       " Data(edge_attr=[22, 3], edge_index=[2, 22], x=[11, 38], y=[1]),\n",
       " Data(edge_attr=[16, 3], edge_index=[2, 16], x=[9, 38], y=[1]),\n",
       " Data(edge_attr=[20, 3], edge_index=[2, 20], x=[10, 38], y=[1]),\n",
       " Data(edge_attr=[34, 3], edge_index=[2, 34], x=[16, 38], y=[1]),\n",
       " Data(edge_attr=[18, 3], edge_index=[2, 18], x=[9, 38], y=[1]),\n",
       " Data(edge_attr=[24, 3], edge_index=[2, 24], x=[11, 38], y=[1]),\n",
       " Data(edge_attr=[22, 3], edge_index=[2, 22], x=[10, 38], y=[1]),\n",
       " Data(edge_attr=[32, 3], edge_index=[2, 32], x=[17, 38], y=[1]),\n",
       " Data(edge_attr=[16, 3], edge_index=[2, 16], x=[9, 38], y=[1])]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data.Batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(batch=[149], edge_attr=[310, 3], edge_index=[2, 310], ptr=[11], x=[149, 38], y=[10])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.from_data_list(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TUDataset' object has no attribute 'max'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-f5f857cb015b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/lafexp/lib/python3.7/site-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36mnum_graphs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TUDataset' object has no attribute 'max'"
     ]
    }
   ],
   "source": [
    "batch.num_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
